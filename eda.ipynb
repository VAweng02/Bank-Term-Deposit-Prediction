{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["df=pd.read_csv(\"https://raw.githubusercontent.com/tassalor1/Bank-Term-Deposit-Prediction/Virginia's-Branch/Bank-Additional-full.csv\")"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>job</th>\n","      <th>marital</th>\n","      <th>education</th>\n","      <th>default</th>\n","      <th>housing</th>\n","      <th>loan</th>\n","      <th>contact</th>\n","      <th>month</th>\n","      <th>year</th>\n","      <th>...</th>\n","      <th>campaign</th>\n","      <th>pdays</th>\n","      <th>previous</th>\n","      <th>poutcome</th>\n","      <th>emp.var.rate</th>\n","      <th>cons.price.idx</th>\n","      <th>cons.conf.idx</th>\n","      <th>euribor3m</th>\n","      <th>nr.employed</th>\n","      <th>y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>56</td>\n","      <td>housemaid</td>\n","      <td>married</td>\n","      <td>basic.4y</td>\n","      <td>no</td>\n","      <td>no</td>\n","      <td>no</td>\n","      <td>telephone</td>\n","      <td>may</td>\n","      <td>2008</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>-1</td>\n","      <td>0</td>\n","      <td>nonexistent</td>\n","      <td>1.1</td>\n","      <td>93.994</td>\n","      <td>-36.4</td>\n","      <td>4.857</td>\n","      <td>5191.0</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>57</td>\n","      <td>services</td>\n","      <td>married</td>\n","      <td>high.school</td>\n","      <td>unknown</td>\n","      <td>no</td>\n","      <td>no</td>\n","      <td>telephone</td>\n","      <td>may</td>\n","      <td>2008</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>-1</td>\n","      <td>0</td>\n","      <td>nonexistent</td>\n","      <td>1.1</td>\n","      <td>93.994</td>\n","      <td>-36.4</td>\n","      <td>4.857</td>\n","      <td>5191.0</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>37</td>\n","      <td>services</td>\n","      <td>married</td>\n","      <td>high.school</td>\n","      <td>no</td>\n","      <td>yes</td>\n","      <td>no</td>\n","      <td>telephone</td>\n","      <td>may</td>\n","      <td>2008</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>-1</td>\n","      <td>0</td>\n","      <td>nonexistent</td>\n","      <td>1.1</td>\n","      <td>93.994</td>\n","      <td>-36.4</td>\n","      <td>4.857</td>\n","      <td>5191.0</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>40</td>\n","      <td>admin.</td>\n","      <td>married</td>\n","      <td>basic.6y</td>\n","      <td>no</td>\n","      <td>no</td>\n","      <td>no</td>\n","      <td>telephone</td>\n","      <td>may</td>\n","      <td>2008</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>-1</td>\n","      <td>0</td>\n","      <td>nonexistent</td>\n","      <td>1.1</td>\n","      <td>93.994</td>\n","      <td>-36.4</td>\n","      <td>4.857</td>\n","      <td>5191.0</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>56</td>\n","      <td>services</td>\n","      <td>married</td>\n","      <td>high.school</td>\n","      <td>no</td>\n","      <td>no</td>\n","      <td>yes</td>\n","      <td>telephone</td>\n","      <td>may</td>\n","      <td>2008</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>-1</td>\n","      <td>0</td>\n","      <td>nonexistent</td>\n","      <td>1.1</td>\n","      <td>93.994</td>\n","      <td>-36.4</td>\n","      <td>4.857</td>\n","      <td>5191.0</td>\n","      <td>no</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 22 columns</p>\n","</div>"],"text/plain":["   age        job  marital    education  default housing loan    contact  \\\n","0   56  housemaid  married     basic.4y       no      no   no  telephone   \n","1   57   services  married  high.school  unknown      no   no  telephone   \n","2   37   services  married  high.school       no     yes   no  telephone   \n","3   40     admin.  married     basic.6y       no      no   no  telephone   \n","4   56   services  married  high.school       no      no  yes  telephone   \n","\n","  month  year  ... campaign  pdays  previous     poutcome  emp.var.rate  \\\n","0   may  2008  ...        1     -1         0  nonexistent           1.1   \n","1   may  2008  ...        1     -1         0  nonexistent           1.1   \n","2   may  2008  ...        1     -1         0  nonexistent           1.1   \n","3   may  2008  ...        1     -1         0  nonexistent           1.1   \n","4   may  2008  ...        1     -1         0  nonexistent           1.1   \n","\n","  cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n","0         93.994          -36.4      4.857       5191.0  no  \n","1         93.994          -36.4      4.857       5191.0  no  \n","2         93.994          -36.4      4.857       5191.0  no  \n","3         93.994          -36.4      4.857       5191.0  no  \n","4         93.994          -36.4      4.857       5191.0  no  \n","\n","[5 rows x 22 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["#replacing \"unknown\" with NaN for ease of filtering\n","df2=df.replace({'Unknown' : np.nan, 'unknown' : np.nan})"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["age                  0\n","job                330\n","marital             80\n","education         1731\n","default           8597\n","housing            990\n","loan               990\n","contact              0\n","month                0\n","year                 0\n","day_of_week          0\n","duration             0\n","campaign             0\n","pdays                0\n","previous             0\n","poutcome             0\n","emp.var.rate         0\n","cons.price.idx       0\n","cons.conf.idx        0\n","euribor3m            0\n","nr.employed          0\n","y                    0\n","dtype: int64"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df2.isnull().sum()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# Replacing NaN in 'housing' and 'loan' with mode values\n","housing=df['housing']\n","df2['housing'] = df2['housing'].fillna(df['housing'].mode()[0])\n","\n","loan=df['loan']\n","df2['loan'] = df2['loan'].fillna(df['loan'].mode()[0])"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# For now replacing NaN back with 'unknown' for default and leaving that as it's own category. The reason for this is that their is an extreme \n","# imbalance in the 'yes'/'no' cases for this feature, with only three data points indicating 'yes'. Yet the number of \"unknown\" cases is so large.\n","# Since classification would be skewed by the imbalance, we are simply keeping it as 'unknown'.\n","\n","df2['default']=df2['default'].replace({np.nan:'unknown'})"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["age                  0\n","job                330\n","marital             80\n","education         1731\n","default              0\n","housing              0\n","loan                 0\n","contact              0\n","month                0\n","year                 0\n","day_of_week          0\n","duration             0\n","campaign             0\n","pdays                0\n","previous             0\n","poutcome             0\n","emp.var.rate         0\n","cons.price.idx       0\n","cons.conf.idx        0\n","euribor3m            0\n","nr.employed          0\n","y                    0\n","dtype: int64"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["df2.isnull().sum() "]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Old Shape:  (41188, 22)\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/wsuser/ipykernel_178/1334269020.py:6: DeprecationWarning: the `interpolation=` argument to percentile was renamed to `method=`, which has additional options.\n","Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n","  Q1 = np.percentile(df['duration'], 25, interpolation = 'midpoint')\n","/tmp/wsuser/ipykernel_178/1334269020.py:7: DeprecationWarning: the `interpolation=` argument to percentile was renamed to `method=`, which has additional options.\n","Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n","  Q3 = np.percentile(df['duration'], 75,interpolation = 'midpoint')\n"]}],"source":["# Identify Outlier Dating\n","\n","import sklearn\n","from sklearn.datasets import load_boston\n","# IQR\n","Q1 = np.percentile(df['duration'], 25, interpolation = 'midpoint')\n","Q3 = np.percentile(df['duration'], 75,interpolation = 'midpoint')\n","IQR = Q3 - Q1\n"," \n","print(\"Old Shape: \", df.shape)\n","\n","# Upper bound\n","upper=Q3+3*IQR\n","\n","# Lower bound is not necessary to define\n","\n","# Removing the outliers\n","df2.drop(df2[df2['duration']>=upper].index,inplace=True)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["#Dropping rows where 'job' and 'marital' contain NaN\n","df2=df2.dropna(subset=['job','marital'])"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["age                  0\n","job                  0\n","marital              0\n","education         1552\n","default              0\n","housing              0\n","loan                 0\n","contact              0\n","month                0\n","year                 0\n","day_of_week          0\n","duration             0\n","campaign             0\n","pdays                0\n","previous             0\n","poutcome             0\n","emp.var.rate         0\n","cons.price.idx       0\n","cons.conf.idx        0\n","euribor3m            0\n","nr.employed          0\n","y                    0\n","dtype: int64"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["df2.isnull().sum() "]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["age                 int64\n","job                object\n","marital            object\n","education          object\n","default            object\n","housing            object\n","loan               object\n","contact            object\n","month              object\n","year                int64\n","day_of_week        object\n","duration            int64\n","campaign            int64\n","pdays               int64\n","previous            int64\n","poutcome           object\n","emp.var.rate      float64\n","cons.price.idx    float64\n","cons.conf.idx     float64\n","euribor3m         float64\n","nr.employed       float64\n","y                  object\n","dtype: object"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["df2.dtypes"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["convert_dict = {'age': float,'year': float,'duration':float,'campaign': float,'pdays': float,'previous': float,'emp.var.rate': float,\n","                'cons.price.idx': float,'cons.conf.idx': float,'euribor3m': float, 'nr.employed': float}\n","\n","df2 = df2.astype(convert_dict)"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>education</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>7</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   education\n","7        NaN\n","10       NaN\n","26       NaN\n","30       NaN\n","31       NaN"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["# Now we must work on the preprocessing ML model to predict the missing values of 'education'. In order to train the model, we must first \n","# remove the missing values.\n","\n","df2_test=df2[df2['education'].isnull()]\n","X_test=df2_test.drop(['education'], axis=1)\n","y_test=pd.DataFrame(df2_test['education'])\n","\n","df2_train=df2[df2['education'].notnull()]\n","X_train=df2_train.drop(['education'],axis=1)\n","y_train=pd.DataFrame(df2_train['education'])\n","\n","X_train.isnull().sum() \n","y_train.head(100)\n","y_test.head()"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["numeric_columns=list(X_train.select_dtypes('float64').columns)\n","categorical_columns=list(X_train.select_dtypes('object').columns)"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>year</th>\n","      <th>duration</th>\n","      <th>campaign</th>\n","      <th>pdays</th>\n","      <th>previous</th>\n","      <th>emp.var.rate</th>\n","      <th>cons.price.idx</th>\n","      <th>cons.conf.idx</th>\n","      <th>euribor3m</th>\n","      <th>nr.employed</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.566437</td>\n","      <td>-0.65347</td>\n","      <td>0.166192</td>\n","      <td>-0.562507</td>\n","      <td>-0.168557</td>\n","      <td>-0.34976</td>\n","      <td>0.650117</td>\n","      <td>0.732708</td>\n","      <td>0.893725</td>\n","      <td>0.713704</td>\n","      <td>0.330044</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.663545</td>\n","      <td>-0.65347</td>\n","      <td>-0.439450</td>\n","      <td>-0.562507</td>\n","      <td>-0.168557</td>\n","      <td>-0.34976</td>\n","      <td>0.650117</td>\n","      <td>0.732708</td>\n","      <td>0.893725</td>\n","      <td>0.713704</td>\n","      <td>0.330044</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.278619</td>\n","      <td>-0.65347</td>\n","      <td>-0.023071</td>\n","      <td>-0.562507</td>\n","      <td>-0.168557</td>\n","      <td>-0.34976</td>\n","      <td>0.650117</td>\n","      <td>0.732708</td>\n","      <td>0.893725</td>\n","      <td>0.713704</td>\n","      <td>0.330044</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.012706</td>\n","      <td>-0.65347</td>\n","      <td>-0.428635</td>\n","      <td>-0.562507</td>\n","      <td>-0.168557</td>\n","      <td>-0.34976</td>\n","      <td>0.650117</td>\n","      <td>0.732708</td>\n","      <td>0.893725</td>\n","      <td>0.713704</td>\n","      <td>0.330044</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.566437</td>\n","      <td>-0.65347</td>\n","      <td>0.414937</td>\n","      <td>-0.562507</td>\n","      <td>-0.168557</td>\n","      <td>-0.34976</td>\n","      <td>0.650117</td>\n","      <td>0.732708</td>\n","      <td>0.893725</td>\n","      <td>0.713704</td>\n","      <td>0.330044</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        age     year  duration  campaign     pdays  previous  emp.var.rate  \\\n","0  1.566437 -0.65347  0.166192 -0.562507 -0.168557  -0.34976      0.650117   \n","1  1.663545 -0.65347 -0.439450 -0.562507 -0.168557  -0.34976      0.650117   \n","2 -0.278619 -0.65347 -0.023071 -0.562507 -0.168557  -0.34976      0.650117   \n","3  0.012706 -0.65347 -0.428635 -0.562507 -0.168557  -0.34976      0.650117   \n","4  1.566437 -0.65347  0.414937 -0.562507 -0.168557  -0.34976      0.650117   \n","\n","   cons.price.idx  cons.conf.idx  euribor3m  nr.employed  \n","0        0.732708       0.893725   0.713704     0.330044  \n","1        0.732708       0.893725   0.713704     0.330044  \n","2        0.732708       0.893725   0.713704     0.330044  \n","3        0.732708       0.893725   0.713704     0.330044  \n","4        0.732708       0.893725   0.713704     0.330044  "]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import StandardScaler,LabelBinarizer,OneHotEncoder\n","from sklearn.ensemble import RandomForestRegressor\n","#import xgboost as xgb\n","\n","scaler = StandardScaler()\n","scaler.fit(X_train[numeric_columns])\n","X_train_scaled = pd.DataFrame(scaler.transform(X_train[numeric_columns]), columns = numeric_columns)\n","X_test_scaled = pd.DataFrame(scaler.transform(X_test[numeric_columns]), columns = numeric_columns) \n","X_train_scaled.head()\n","\n"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n","/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n","/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>x0_basic.4y</th>\n","      <th>x0_basic.6y</th>\n","      <th>x0_basic.9y</th>\n","      <th>x0_high.school</th>\n","      <th>x0_illiterate</th>\n","      <th>x0_professional.course</th>\n","      <th>x0_university.degree</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   x0_basic.4y  x0_basic.6y  x0_basic.9y  x0_high.school  x0_illiterate  \\\n","0          1.0          0.0          0.0             0.0            0.0   \n","1          0.0          0.0          0.0             1.0            0.0   \n","2          0.0          0.0          0.0             1.0            0.0   \n","3          0.0          1.0          0.0             0.0            0.0   \n","4          0.0          0.0          0.0             1.0            0.0   \n","\n","   x0_professional.course  x0_university.degree  \n","0                     0.0                   0.0  \n","1                     0.0                   0.0  \n","2                     0.0                   0.0  \n","3                     0.0                   0.0  \n","4                     0.0                   0.0  "]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":["encoder = OneHotEncoder(sparse=False)\n","\n","encoder.fit_transform(X_train[categorical_columns])\n","\n","df_temp=encoder.transform(X_train[categorical_columns])\n","X_train_encoded=pd.DataFrame(df_temp,columns=encoder.get_feature_names())\n","\n","df_temp2=encoder.transform(X_test[categorical_columns])\n","X_test_encoded=pd.DataFrame(df_temp2,columns=encoder.get_feature_names())\n","\n","encoder.fit_transform(y_train)\n","\n","df_temp3=encoder.transform(y_train)\n","y_columns=encoder.get_feature_names()\n","y_train_encoded=pd.DataFrame(df_temp3,columns=encoder.get_feature_names())\n","\n","y_train_encoded.head()"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[],"source":["Transformed_X_train= pd.concat([X_train_scaled,X_train_encoded], axis=1)\n","Transformed_X_test= pd.concat([X_test_scaled,X_test_encoded], axis=1)"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"data":{"text/html":["<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"],"text/plain":["RandomForestRegressor()"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["clf =RandomForestRegressor()\n","clf.fit(Transformed_X_train, y_train_encoded)"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["y_pred = clf.predict(Transformed_X_test)"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>x0_basic.4y</th>\n","      <th>x0_basic.6y</th>\n","      <th>x0_basic.9y</th>\n","      <th>x0_high.school</th>\n","      <th>x0_illiterate</th>\n","      <th>x0_professional.course</th>\n","      <th>x0_university.degree</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.29</td>\n","      <td>0.07</td>\n","      <td>0.63</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.01</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.13</td>\n","      <td>0.01</td>\n","      <td>0.85</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.01</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.27</td>\n","      <td>0.03</td>\n","      <td>0.17</td>\n","      <td>0.05</td>\n","      <td>0.0</td>\n","      <td>0.22</td>\n","      <td>0.26</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.02</td>\n","      <td>0.02</td>\n","      <td>0.10</td>\n","      <td>0.34</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.52</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.16</td>\n","      <td>0.02</td>\n","      <td>0.12</td>\n","      <td>0.03</td>\n","      <td>0.0</td>\n","      <td>0.36</td>\n","      <td>0.31</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1547</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.01</td>\n","      <td>0.75</td>\n","      <td>0.0</td>\n","      <td>0.07</td>\n","      <td>0.17</td>\n","    </tr>\n","    <tr>\n","      <th>1548</th>\n","      <td>0.14</td>\n","      <td>0.00</td>\n","      <td>0.06</td>\n","      <td>0.07</td>\n","      <td>0.0</td>\n","      <td>0.24</td>\n","      <td>0.49</td>\n","    </tr>\n","    <tr>\n","      <th>1549</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.01</td>\n","      <td>0.80</td>\n","      <td>0.0</td>\n","      <td>0.01</td>\n","      <td>0.18</td>\n","    </tr>\n","    <tr>\n","      <th>1550</th>\n","      <td>0.02</td>\n","      <td>0.04</td>\n","      <td>0.14</td>\n","      <td>0.16</td>\n","      <td>0.0</td>\n","      <td>0.40</td>\n","      <td>0.24</td>\n","    </tr>\n","    <tr>\n","      <th>1551</th>\n","      <td>0.02</td>\n","      <td>0.00</td>\n","      <td>0.05</td>\n","      <td>0.31</td>\n","      <td>0.0</td>\n","      <td>0.29</td>\n","      <td>0.33</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1552 rows Ã— 7 columns</p>\n","</div>"],"text/plain":["      x0_basic.4y  x0_basic.6y  x0_basic.9y  x0_high.school  x0_illiterate  \\\n","0            0.29         0.07         0.63            0.00            0.0   \n","1            0.13         0.01         0.85            0.00            0.0   \n","2            0.27         0.03         0.17            0.05            0.0   \n","3            0.02         0.02         0.10            0.34            0.0   \n","4            0.16         0.02         0.12            0.03            0.0   \n","...           ...          ...          ...             ...            ...   \n","1547         0.00         0.00         0.01            0.75            0.0   \n","1548         0.14         0.00         0.06            0.07            0.0   \n","1549         0.00         0.00         0.01            0.80            0.0   \n","1550         0.02         0.04         0.14            0.16            0.0   \n","1551         0.02         0.00         0.05            0.31            0.0   \n","\n","      x0_professional.course  x0_university.degree  \n","0                       0.01                  0.00  \n","1                       0.01                  0.00  \n","2                       0.22                  0.26  \n","3                       0.00                  0.52  \n","4                       0.36                  0.31  \n","...                      ...                   ...  \n","1547                    0.07                  0.17  \n","1548                    0.24                  0.49  \n","1549                    0.01                  0.18  \n","1550                    0.40                  0.24  \n","1551                    0.29                  0.33  \n","\n","[1552 rows x 7 columns]"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["y_pred=pd.DataFrame(y_pred,columns=y_columns)\n","y_pred"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Now that I have the predicted values for education, I can plug them back into the original dataset.\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Connor's Comments:\n","The EDA process in the provided code is well-executed in several aspects. The Virginia demonstrates a comprehensive approach to data preprocessing, including handling missing values, outlier detection, and data type conversions, ensuring a clean dataset for analysis. Points to improve: Commenting: Would be helpful to provide more comments at each step for readability / Formatting: Code contains Inconsistent formatting and spacing / Model Choice: Education is a categorial variable so random forrest regressor isnâ€™t the best choice of model - use a classifier / Model Evaluation: The model has no evaluation of performance - use something like a classification report to assess this"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Vincent's Comment: The process of removing certain rows based on features that had a small amount of missing values were executed well. Virginia also used the method of replacing missing values with the mode with two featues, which is a strategy that we agreed upon. Furthermore, Virginia used a random forest along with a regressor, which the model mistakenly predicted continuous numerical values for default. However, default is a binary classification. Thus, one suggestion that we discussed at our meeting was changing the regressor to a different ML method to ensure that it predicts either 1 or 0 for default. Overall, the data cleansing and transformation was job really well."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Kefan's comments: Virgina's way of dropping nan values in \"jobs\" and \"marital\" columns and replacing with mode in \"housing\" and \"loan\" columns is the same as my approach, and I have the same opinion as Connor that regressor is not suitable in this case but it only works for continuous variables, and it will return decimals with categorical encoding."]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"celltoolbar":"Raw Cell Format","kernelspec":{"display_name":"Python 3.10","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":1}
